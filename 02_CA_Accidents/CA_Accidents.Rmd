```{R message=FALSE, warning=FALSE}
library(DBI)
library(tidymodels)
library(tidyverse)
library(data.table)
library(ggrepel)
library(tictoc)
```

```{r}
#TODO add DL link for sqlite db

setwd("D:/ML Exercises/Rstats-Excercises/02_CA_Accidents")

dir.create("rda/", showWarnings = FALSE)

if (!file.exists("rda/collision_data.Rdata")) {
    
    message("Extracting collision data from sqlite database...")
    
    # Create an ephemeral in-memory RSQLite database
    con <- dbConnect(RSQLite::SQLite(), "switrs.sqlite")
    
    dbListTables(con)
    
    case_ids <- dbGetQuery(con, "SELECT * FROM case_ids ORDER BY RANDOM() LIMIT 500000") %>%
        as.data.table()
    collisions <- dbGetQuery(con, "SELECT * FROM collisions ORDER BY RANDOM() LIMIT 500000") %>%
        as.data.table()
    parties <- dbGetQuery(con, "SELECT * FROM parties ORDER BY RANDOM() LIMIT 500000") %>%
        as.data.table()
    victims <- dbGetQuery(con, "SELECT * FROM victims ORDER BY RANDOM() LIMIT 500000") %>%
        as.data.table()
    
    dbDisconnect(conn = con)
    rm(con)
    
    save.image("rda/collision_data.Rdata")
} else {
    message("Loading collision data from R data file...")
    load("rda/collision_data.Rdata")
}
```
Dealing with this much data is unwieldy and takes too long. Let's subset the rows so we are working with a representative fraction of the tables. We can load the original files back up for our final analyses later.


```{R}
# if(!file.exists("rda/victims_skim.Rdata")) {
#     message("Skimming all tables seperately...")
#     collisions_skim <- skimr::skim(collisions)
#     save(collisions_skim, file = "rda/collisions_skim.Rdata")
#     
#     case_ids_skim <- skimr::skim(case_ids)
#     save(case_ids_skim, file = "rda/case_ids_skim.Rdata")
#     
#     parties_skim <- skimr::skim(parties)
#     save(parties_skim, file = "rda/parties_skim.Rdata")
#     
#     victims_skim <- skimr::skim(victims)
#     save(victims_skim, file = "rda/victims_skim.Rdata")
# } else {
#     for (i in Sys.glob(file.path("rda/*_skim.Rdata"))) {
#         load(i)
#     }
# }
```

There are so many questions we could answer here. For example, I'm immediately interested in `victims$victim_degree_of_injury`:

```{r}
table(victims$victim_degree_of_injury)
```

Just to start out, let's see if we could build a functioning `XGboost` model to see if predict if a victim gets killed based on the collision data.

```{r}
setkey(collisions, case_id)
setkey(victims, case_id)

col_vict <- merge(collisions, victims) %>%
    select(
        weather_1,
        location_type,
        tow_away,
        killed_victims,
        party_count,
        pcf_violation_category,
        hit_and_run,
        type_of_collision,
        pedestrian_action,
        road_surface,
        road_condition_1,
        lighting,
        pedestrian_collision,
        bicycle_collision,
        motorcycle_collision,
        truck_collision,
        alcohol_involved,
        ends_with("_killed_count"),
        starts_with("victim_"),
        collision_time
    ) %>% 
    mutate_if(is.character, factor)

col_vict$victim_degree_of_injury <- recode(
    col_vict$victim_degree_of_injury,
    `5` = "suspected serious injury",
    `6` = "suspected minor injury",
    `7` = "possible injury"
)
```

```{r}
col_vict %>%
    select(hit_and_run, victim_degree_of_injury) %>%
    filter(hit_and_run == "felony") %>%
    group_by(victim_degree_of_injury) %>%
    summarise(count = n()) %>%
    ggplot(aes(
        x = fct_reorder(victim_degree_of_injury, count),
        y = count,
        fill = victim_degree_of_injury
    )) +
    geom_bar(stat = "identity") +
    ylab("n of Hit-and-Runs") +
    xlab("Victim Injury Type") + 
    theme(axis.text.x = element_text(face = "bold", angle = 45, size = 7, hjust = 1))

nrow(col_vict)
```

Wow, that was actually pretty underwhelming. I though there would be a higher number of kills for hit and runs than anything else.

```{r}
col_vict %>% 
    select(alcohol_involved, victim_degree_of_injury) %>%
    mutate(alcohol_involved = as.factor(ifelse(is.na(alcohol_involved), "NO", "YES"))) %>% 
    table() %>% 
    as.data.table() %>% 
    group_by(victim_degree_of_injury) %>% 
    mutate(ratio = N[alcohol_involved == "YES"] / N[alcohol_involved == "NO"]) %>% 
    mutate(N = N[alcohol_involved == "YES"] + N[alcohol_involved == "NO"]) %>% 
    mutate(alcohol_involved = NULL) %>% 
    distinct() %>% 
    ggplot(aes(x = fct_reorder(victim_degree_of_injury, ratio), y = ratio, fill = victim_degree_of_injury)) + 
    geom_bar(stat = "identity") +
    geom_text(aes(label = N), position = position_dodge(width=0.9), vjust=-0.25)

nrow(col_vict)
```

We can see that among those who were killed, there was the greatest ratio of drunk-driving involved vs. not involved. Of course, there is a small sample size for `killed`, but we can observe if this trend holds for larger than 50k samples later.

Let's just get started. We all know these variables are going to effect death outcomes. 

## Building Model ####

```{r}
library(usemodels)

vic_init <- initial_split(col_vict, strata = victim_degree_of_injury)

vic_train <- training(vic_init)
vic_test <- testing(vic_init)

use_xgboost(victim_degree_of_injury ~ ., vic_train, verbose = TRUE)
```

Isn't that neat? `{usemodels}` will generate a model workflow for you, all you need to do is specify which type of model you would like to use. You also likely need to go through and modify the workflow that it gives you to fit your particular circumstance.

```{r}
xgboost_recipe <- 
  recipe(formula = victim_degree_of_injury ~ ., data = vic_train) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% 
  step_zv(all_predictors()) %>% 
  step_unknown(all_nominal())
```

Here's the `{usemodels}`-generated `recipe` with a few changes. Let's go through each step one-by-one.

`step_novel` takes will take "previously unseen" factor levels to a new value, by default named "`new`". This step is only really affects testing data; training data is how this determines what is "new" or not.

`step_dummy` creates dummy variables for nominal predictors, which allows some learning algorithms (such as tree-based ones), to use categorical variables. `one_hot = TRUE` means that all of the factor levels for that nominal predictor will be encoded as column witn binary values, instead of the default behavior, which creates `n - 1` columns to indicate the `nth` column through exclusion.

`step_zv` eliminates predictors that have no variance.

`step_unknown` simply converts all missing values for nominal predictors into a new factor level, `unknown` (by default).

```{r}
xgboost_spec <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), 
    loss_reduction = tune(), sample_size = tune(), mtry = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost") 
```

Above, we specified our trees. XGBoost, among other learning models, have "tuning parameters," which are parameters that cannot be learned from the data at hand, they must be either manually set, or better yet, tuned to the optimal values. 

```{r}
xgboost_workflow <- 
  workflow() %>% 
  add_recipe(xgboost_recipe) %>% 
  add_model(xgboost_spec)
```

```{r}
if (!file.exists(file.path("tunedXG.Rdata"))) {
    message("Tuning the model with a 10-fold cross-validation resample. This might take 4.5 hours on a 24-thread CPU like the Ryzen 3900x")
    xgb_rs <- vfold_cv(vic_train, v = 10)
    
    xgb_grid <- grid_latin_hypercube(
        trees(),
        tree_depth(),
        min_n(),
        loss_reduction(),
        sample_size = sample_prop(),
        finalize(mtry(), vic_train),
        learn_rate(),
        size = 20
    )
    
    doParallel::registerDoParallel(cores = parallel::detectCores())
    set.seed(5598)
    tic()
    xgboost_tune <-
        tune_grid(
            xgboost_workflow,
            resamples = xgb_rs,
            grid = xgb_grid,
            control = control_grid(save_pred = TRUE, verbose = TRUE)
        )
    toc()
} else {
  load("tunedXG.Rdata")  
}
```

`xgboost_tune` took ~4.6 hours to complete on my Ryzen 3900x 12-core/24-thread CPU.

After we stick our recipe and model into a `workflow` object, we begin the tuning process. We are going to use a simple 10-fold cross validation scheme. We then define the grid of performance metrics we hope to calculate for each one of our hyperparameters, and we set the size to 

```{r}
    xgboost_tune %>% collect_metrics() %>% 
        filter(.metric == "roc_auc") %>% 
        select(mean, mtry:sample_size) %>% 
        pivot_longer(mtry:sample_size, 
                     names_to = "parameter", 
                     values_to = "value") %>% 
        ggplot(aes(value, mean, color = parameter)) +
        geom_point(show.legend = FALSE) + 
        facet_wrap(~ parameter, scales = "free_x")
```

Okay, so we can definitely tell that we did better with more trees. High learn rates also seem to do better. High `mtry` seems to consistently hit higher `roc_auc` with higher values. `min_n` with lower. Okay. 

```{r}
show_best(xgboost_tune, "roc_auc")

best_auc <- select_best(xgboost_tune, "roc_auc")
```

```{r}
final_xgb <- finalize_workflow(xgboost_workflow, best_auc)
```

```{r}
library(vip)

vip_plot <- final_xgb %>% fit(data = vic_train) %>% 
    pull_workflow_fit() %>% 
    vip(geom = "point", num_features = 22L)
```
Here is what the codes correspond to according to this [here](https://tims.berkeley.edu/help/SWITRS.php):
* `victim_role_X2` is `Passenger`
* `victim_seating_position_X2` and `victim_seating_position_X3` are `Passenger`
* `victim_role_X1` is `Driver`
* `victim_safety_equipment_1_L` is `Air Bag Deployed`

These variables *are the most important in explaining `victim_degree_of_injury`*. 


```{r}
final_res <- last_fit(final_xgb, vic_init)

final_res %>% collect_metrics()
```

Okay. 0.773. Not bad. 

```{r}
final_res %>% collect_predictions() %>%
    select(.pred_class, victim_degree_of_injury) %>%
    mutate(pred = ifelse(.pred_class == victim_degree_of_injury, TRUE, FALSE)) %>% 
    conf_mat(truth = victim_degree_of_injury, estimate = .pred_class) %>% 
    autoplot(type = "heatmap") +
    theme(axis.text.x = element_text(face = "bold", angle = 45, size = 7, hjust = 1)) 
```

This model is apparently best at predicting `no injury` and `complaint of pain`. It often gets the two mixed up with each other. Otherwise it's not really a remarkable model and in fact only accurately predicts `killed` 3 times. Wow. How mediocre. Maybe we can try this again but remove the most frequent predictors? Just to make it more interesting?











